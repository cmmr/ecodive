<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Information-Theoretic and Probabilistic Distances — divergence • ecodive</title><!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png"><link rel="icon" type="”image/svg+xml”" href="../favicon.svg"><link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png"><link rel="icon" sizes="any" href="../favicon.ico"><link rel="manifest" href="../site.webmanifest"><!-- katex math --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" integrity="sha384-7zkQWkzuo3B5mTepMUcHkMB5jZaolc2xDwL6VFqjFALcbeS9Ggm/Yr2r3Dy4lfFg" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script><script src="../katex-auto.js"></script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/Noto_Sans-0.4.10/font.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet"><meta property="og:title" content="Information-Theoretic and Probabilistic Distances — divergence"><meta name="description" content="This category of metrics is derived from information theory and probability
theory. They conceptualize sample composition vectors as discrete probability
distributions and measure the dissimilarity by quantifying the difference
between these distributions."><meta property="og:description" content="This category of metrics is derived from information theory and probability
theory. They conceptualize sample composition vectors as discrete probability
distributions and measure the dissimilarity by quantifying the difference
between these distributions."><meta property="og:image" content="https://cmmr.github.io/ecodive/logo.png"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">ecodive</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0.0.9002</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="../articles/ecodive.html">Get started</a></li>
<li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/adiv.html">Alpha Diversity</a></li>
    <li><a class="dropdown-item" href="../articles/bdiv.html">Beta Diversity</a></li>
    <li><a class="dropdown-item" href="../articles/bdiv_guide.html">Selecting a Beta Diversity Metric</a></li>
    <li><a class="dropdown-item" href="../articles/benchmark.html">Benchmarks</a></li>
    <li><a class="dropdown-item" href="../articles/unifrac.html">UniFrac Calculations</a></li>
  </ul></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/cmmr/ecodive/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Information-Theoretic and Probabilistic Distances</h1>
      <small class="dont-index">Source: <a href="https://github.com/cmmr/ecodive/blob/HEAD/R/bdiv_theoretic.r" class="external-link"><code>R/bdiv_theoretic.r</code></a></small>
      <div class="d-none name"><code>bdiv_theoretic.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>This category of metrics is derived from information theory and probability
theory. They conceptualize sample composition vectors as discrete probability
distributions and measure the dissimilarity by quantifying the difference
between these distributions.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">divergence</span><span class="op">(</span><span class="va">counts</span>, pairs <span class="op">=</span> <span class="cn">NULL</span>, cpus <span class="op">=</span> <span class="fu"><a href="n_cpus.html">n_cpus</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">jensen</span><span class="op">(</span><span class="va">counts</span>, pairs <span class="op">=</span> <span class="cn">NULL</span>, cpus <span class="op">=</span> <span class="fu"><a href="n_cpus.html">n_cpus</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">jsd</span><span class="op">(</span><span class="va">counts</span>, pairs <span class="op">=</span> <span class="cn">NULL</span>, cpus <span class="op">=</span> <span class="fu"><a href="n_cpus.html">n_cpus</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">prob_symm</span><span class="op">(</span><span class="va">counts</span>, pairs <span class="op">=</span> <span class="cn">NULL</span>, cpus <span class="op">=</span> <span class="fu"><a href="n_cpus.html">n_cpus</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">squared_chisq</span><span class="op">(</span><span class="va">counts</span>, pairs <span class="op">=</span> <span class="cn">NULL</span>, cpus <span class="op">=</span> <span class="fu"><a href="n_cpus.html">n_cpus</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">topsoe</span><span class="op">(</span><span class="va">counts</span>, pairs <span class="op">=</span> <span class="cn">NULL</span>, cpus <span class="op">=</span> <span class="fu"><a href="n_cpus.html">n_cpus</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-counts">counts<a class="anchor" aria-label="anchor" href="#arg-counts"></a></dt>
<dd><p>A numeric matrix of count data where each column is a sample,
and each row is a feature. Any object coercible with <code><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix()</a></code>
can be given here, as well as <code>phyloseq</code>, <code>rbiom</code>,
<code>SummarizedExperiment</code>, and <code>TreeSummarizedExperiment</code> objects.</p></dd>


<dt id="arg-pairs">pairs<a class="anchor" aria-label="anchor" href="#arg-pairs"></a></dt>
<dd><p>Which combinations of samples should distances be
calculated for? The default value (<code>NULL</code>) calculates all-vs-all.
Provide a numeric or logical vector specifying positions in the
distance matrix to calculate. See examples.</p></dd>


<dt id="arg-cpus">cpus<a class="anchor" aria-label="anchor" href="#arg-cpus"></a></dt>
<dd><p>How many parallel processing threads should be used. The
default, <code><a href="n_cpus.html">n_cpus()</a></code>, will use all logical CPU cores.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>A <code>dist</code> object.</p>
    </div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>

<div class="section">
<h3 id="divergence-based-metrics-jensen-shannon-and-topsoe">Divergence-Based Metrics: Jensen-Shannon and Topsoe<a class="anchor" aria-label="anchor" href="#divergence-based-metrics-jensen-shannon-and-topsoe"></a></h3>

<ul><li><p>The <strong>Jensen-Shannon Divergence (JSD)</strong> is a widely used method for comparing probability distributions. It is a symmetric and bounded (ranging from 0 to 1) version of the more famous but asymmetric Kullback-Leibler (KL) divergence. JSD effectively measures the "information gain" or "surprise" in discriminating between the two distributions. Its square root, the <strong>Jensen-Shannon distance</strong>, is a true metric.</p></li>
<li><p>The <strong>Topsoe distance</strong> is another metric from the same family of information-theoretic measures, sharing similar properties and applications. These metrics are robust for proportional data and are less sensitive to outliers than some geometric distances.</p></li>
</ul></div>

<div class="section">
<h3 id="chi-squared-based-distances">Chi-Squared Based Distances<a class="anchor" aria-label="anchor" href="#chi-squared-based-distances"></a></h3>


<p>The <strong>Squared Chi-Squared</strong> and <strong>Probabilistic Symmetric Chi-Squared</strong>
distances are based on the chi-squared (\(\chi^2\)) statistic, which is
commonly used in contingency table tests to assess the independence of two
categorical variables. In the context of beta diversity, it compares the
observed species proportions in two communities against what would be
expected if they were drawn from the same underlying distribution. This makes
it particularly sensitive to differences in the relative proportions of
species, even when absolute abundances are low. It is a powerful tool for
detecting associations and differences in frequency data.</p>
</div>

    </div>
    <div class="section level2">
    <h2 id="calculation">Calculation<a class="anchor" aria-label="anchor" href="#calculation"></a></h2>



<p>Given:</p>
<dl><dt>\(x\): </dt>
<dd><p>Feature counts for the first sample.</p></dd>

<dt>\(y\): </dt>
<dd><p>Feature counts for the second sample.</p></dd>

<dt>\(n\): </dt>
<dd><p>The number of features.</p></dd>


</dl><p><strong>Jensen-Shannon divergence (JSD)</strong> <code>jsd()</code></p>
<p>$$D = \displaystyle \frac{1}{2}\left[\sum_{i=1}^{n}x_i\ln\left(\frac{2x_i}{x_i + y_i}\right) + \sum_{i}y_i\ln\left(\frac{2y_i}{x_i + y_i}\right)\right]$$</p>
<p><strong>Jensen-Shannon distance</strong> <code>jensen()</code></p>
<p>$$D = \displaystyle \sqrt{\frac{1}{2}\left[\sum_{i=1}^{n}x_i\ln\left(\frac{2x_i}{x_i + y_i}\right) + \sum_{i}y_i\ln\left(\frac{2y_i}{x_i + y_i}\right)\right]}$$</p>
<p><strong>Probabilistic Symmetric Chi-Squared distance</strong> <code>prob_symm()</code></p>
<p>$$D = \displaystyle 2\sum_{i=1}^{n}\frac{(x_i - y_i)^2}{x_i + y_i}$$</p>
<p><strong>Squared Chi-Squared distance</strong> <code>squared_chisq()</code></p>
<p>$$D = \displaystyle \sum_{i=1}^{n}\frac{(x_i - y_i)^2}{x_i + y_i}$$</p>
<p><strong>Topsoe distance</strong> <code>topsoe()</code></p>
<p>$$D = \displaystyle \left[\sum_{i=1}^{n}x_i\ln\left(\frac{2x_i}{x_i + y_i}\right) + \sum_{i}y_i\ln\left(\frac{2y_i}{x_i + y_i}\right)\right]$$</p>
<p></p><div class="sourceCode"><pre><code><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a>  x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">6</span>)</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a>  y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">8</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">5</span>)</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>  <span class="co"># Jensen-Shannon Divergence (JSD)</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>  <span class="fu">sum</span>(x <span class="sc">*</span> <span class="fu">log</span>(<span class="dv">2</span> <span class="sc">*</span> x <span class="sc">/</span> (x<span class="sc">+</span>y)), y <span class="sc">*</span> <span class="fu">log</span>(<span class="dv">2</span> <span class="sc">*</span> y <span class="sc">/</span> (x<span class="sc">+</span>y))) <span class="sc">/</span> <span class="dv">2</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>  <span class="co">#&gt; [1] 2.400612</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>  <span class="co"># Jensen-Shannon distance (jensen)</span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>  <span class="fu">sqrt</span>(<span class="fu">sum</span>(x <span class="sc">*</span> <span class="fu">log</span>(<span class="dv">2</span> <span class="sc">*</span> x <span class="sc">/</span> (x<span class="sc">+</span>y)), y <span class="sc">*</span> <span class="fu">log</span>(<span class="dv">2</span> <span class="sc">*</span> y <span class="sc">/</span> (x<span class="sc">+</span>y))) <span class="sc">/</span> <span class="dv">2</span>)</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a>  <span class="co">#&gt; [1] 2.400612</span></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>  <span class="co"># Topsoe</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>  <span class="fu">sum</span>(x <span class="sc">*</span> <span class="fu">log</span>(<span class="dv">2</span> <span class="sc">*</span> x <span class="sc">/</span> (x<span class="sc">+</span>y)), y <span class="sc">*</span> <span class="fu">log</span>(<span class="dv">2</span> <span class="sc">*</span> y <span class="sc">/</span> (x<span class="sc">+</span>y)))</span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>  <span class="co">#&gt; [1] 4.801224</span></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a>  <span class="co"># Divergence</span></span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>  <span class="dv">2</span> <span class="sc">*</span> <span class="fu">sum</span>((x <span class="sc">-</span> y)<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> (x <span class="sc">+</span> y)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>  <span class="co">#&gt; [1] 2.668628</span></span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a>  <span class="co"># Probabilistic Symmetric Chi-Squared</span></span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a>  <span class="dv">2</span> <span class="sc">*</span> <span class="fu">sum</span>((x <span class="sc">-</span> y)<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> (x <span class="sc">+</span> y))</span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a>  <span class="co">#&gt; [1] 17.33737</span></span>
<span id="cb1-23"><a href="#cb1-23" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" tabindex="-1"></a>  <span class="co"># Squared Chi-Squared</span></span>
<span id="cb1-25"><a href="#cb1-25" tabindex="-1"></a>  <span class="fu">sum</span>((x <span class="sc">-</span> y)<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> (x <span class="sc">+</span> y))</span>
<span id="cb1-26"><a href="#cb1-26" tabindex="-1"></a>  <span class="co">#&gt; [1] 8.668687</span></span></code></pre><p></p></div>
    </div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>
    <p>Cha, S.-H. (2007). Comprehensive survey on distance/similarity measures
between probability density functions. <em>International Journal of Mathematical
Models and Methods in Applied Sciences</em>, 1(4), 300–307.</p>
<p>Levy, A., Shalom, B. R., &amp; Chalamish, M. (2024). A guide to similarity
measures. <em>arXiv</em>. <a href="https://doi.org/10.48550/arXiv.2408.07706v1" class="external-link">doi:10.48550/arXiv.2408.07706v1</a></p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span>    <span class="co"># Example counts matrix</span></span></span>
<span class="r-in"><span>    <span class="va">ex_counts</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span>                   Saliva Gums Nose Stool</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Streptococcus        162  793   22     1</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Bacteroides            2    4    2   611</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Corynebacterium        0    0  498     1</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Haemophilus          180   87    2     1</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Propionibacterium      1    1  251     0</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Staphylococcus         0    1  236     1</span>
<span class="r-in"><span>    </span></span>
<span class="r-in"><span>    <span class="fu">divergence</span><span class="op">(</span><span class="va">ex_counts</span><span class="op">)</span></span></span>
<span class="r-err co"><span class="r-pr">#&gt;</span> <span class="error">Error in validate_normalized(&lt;environment&gt;):</span> could not find function "validate_normalized"</span>
<span class="r-in"><span>    </span></span>
<span class="r-in"><span>    <span class="fu">jensen</span><span class="op">(</span><span class="va">ex_counts</span><span class="op">)</span></span></span>
<span class="r-err co"><span class="r-pr">#&gt;</span> <span class="error">Error in validate_normalized(&lt;environment&gt;):</span> could not find function "validate_normalized"</span>
<span class="r-in"><span>    </span></span>
<span class="r-in"><span>    <span class="fu">jsd</span><span class="op">(</span><span class="va">ex_counts</span><span class="op">)</span></span></span>
<span class="r-err co"><span class="r-pr">#&gt;</span> <span class="error">Error in validate_normalized(&lt;environment&gt;):</span> could not find function "validate_normalized"</span>
<span class="r-in"><span>    </span></span>
<span class="r-in"><span>    <span class="fu">prob_symm</span><span class="op">(</span><span class="va">ex_counts</span><span class="op">)</span></span></span>
<span class="r-err co"><span class="r-pr">#&gt;</span> <span class="error">Error in validate_normalized(&lt;environment&gt;):</span> could not find function "validate_normalized"</span>
<span class="r-in"><span>    </span></span>
<span class="r-in"><span>    <span class="fu">squared_chi</span><span class="op">(</span><span class="va">ex_counts</span><span class="op">)</span></span></span>
<span class="r-err co"><span class="r-pr">#&gt;</span> <span class="error">Error in squared_chi(ex_counts):</span> could not find function "squared_chi"</span>
<span class="r-in"><span>    </span></span>
<span class="r-in"><span>    <span class="fu">topsoe</span><span class="op">(</span><span class="va">ex_counts</span><span class="op">)</span></span></span>
<span class="r-err co"><span class="r-pr">#&gt;</span> <span class="error">Error in validate_normalized(&lt;environment&gt;):</span> could not find function "validate_normalized"</span>
<span class="r-in"><span>    </span></span>
<span class="r-in"><span>    <span class="co"># Only calculate distances for A vs all.</span></span></span>
<span class="r-in"><span>    <span class="fu">divergence</span><span class="op">(</span><span class="va">ex_counts</span>, pairs <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">)</span></span></span>
<span class="r-err co"><span class="r-pr">#&gt;</span> <span class="error">Error in validate_normalized(&lt;environment&gt;):</span> could not find function "validate_normalized"</span>
<span class="r-in"><span>    </span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Daniel P. Smith, Alkek Center for Metagenomics and Microbiome Research.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer></div>





  </body></html>

